{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOnn79XlqPnF",
        "outputId": "409e4bef-869e-41b3-cba4-214a1b8d7dac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['']\n",
            "['']\n",
            "['']\n",
            "['']\n",
            "['']\n",
            "['']\n",
            "['']\n",
            "['']\n",
            "['', 'дизопирамид', 'прокаин', 'прокаинамид', 'хинидин']\n",
            "['', 'амиодарон', 'бретилия тозилат', 'дронедарон', 'ибутилид', 'соталол']\n",
            "['']\n",
            "['']\n",
            "['', 'амисульприд', 'галоперидол', 'дроперидол', 'левомепромазин', 'пимозид', 'промазин', 'сертиндол', 'сультоприд', 'тиаприд', 'тиоридазин', 'трифлуоперазин', 'флуфеназин', 'хлорпромазин']\n",
            "['', 'серотонин', 'циталопрам', 'эсциталопрам']\n",
            "['', 'азитромицин', 'кларитромицин', 'левофлоксацин', 'моксифлоксацин', 'офлоксацин', 'рокситромицин', 'спарфлоксацин', 'спирамицин', 'ципрофлоксацин', 'эритромицин']\n",
            "['', 'вориконазол', 'итраконазол', 'кетоконазол', 'флуконазол']\n",
            "['', 'мефлохин', 'хинин', 'хлорохин']\n",
            "['', 'пентамидин']\n",
            "['', 'бепридил', 'ранолазин']\n",
            "['', 'вандетаниб', 'мышьяка триоксид', 'оксалиплатин', 'такролимус']\n",
            "['', 'домперидон', 'ондансетрон']\n",
            "['', 'цизаприд']\n",
            "['', 'астемизол', 'гистамин', 'терфенадин']\n",
            "['', 'анагрелид', 'кетансерин', 'пробукол', 'пропофол', 'севофлуран', 'серин', 'терлипрессин', 'цилостазол']\n",
            "['', 'верапамил', 'дилтиазем', 'мед']\n",
            "['']\n",
            "['', 'гопантеновая кислота', 'пантогам']\n",
            "['', 'барбитал', 'глицин', 'карбамазепин', 'пантогам', 'фенобарбитал']\n",
            "['', 'прокаин']\n",
            "['']\n",
            "['', 'хлорамфеникол']\n",
            "['', 'клиндамицин', 'линкомицин', 'хлорамфеникол', 'эритромицин']\n",
            "['']\n",
            "['', 'хлорамфеникол']\n",
            "['', 'клиндамицин', 'линкомицин', 'хлорамфеникол', 'эритромицин']\n",
            "['']\n",
            "['']\n",
            "['', 'хлорамфеникол']\n",
            "['']\n",
            "['']\n",
            "['', 'хлорамфеникол']\n",
            "['']\n",
            "['', 'клиндамицин', 'линкомицин', 'эритромицин']\n",
            "['']\n",
            "['']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import unicodedata\n",
        "import html\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('punkt')\n",
        "import re\n",
        "import csv\n",
        "\n",
        "with open(\"/content/Текстовый документ.txt\", 'r',encoding='utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "# Функция для извлечения даты изменения инструкции\n",
        "def extract_date(text):\n",
        "    match = re.search(r'\\(от (.*?)\\)', text)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "# Функция для левой части\n",
        "def left_drug(text):\n",
        "    match = re.search(r'ДВ:\\s*([^;]+)', text)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "# Функция для извлечения препарата\n",
        "def extract_drug(text):\n",
        "    match = re.search(r'ДВ:\\s*([^;]+)', text)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "# Функция для извлечения ID инструкции\n",
        "def extract_id(text):\n",
        "    match = re.search(r'DescID: (\\d+)', text)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "# Функция для извлечения лекарственной формы\n",
        "def extract_form(text):\n",
        "    match = re.search(r'ЛФ:\\s*([^;]+)', text)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "# Функция для обработки правила взаимодействия\n",
        "def extract_interaction_rules(text, drug_names_file):\n",
        "    # Нормализация кодировки\n",
        "    text = unicodedata.normalize('NFKC', html.unescape(text))\n",
        "    with open(drug_names_file, 'r', encoding='utf-8') as f:\n",
        "        drug_names = [unicodedata.normalize('NFKC', html.unescape(name.strip().lower())) for name in f.readlines()]\n",
        "        text = text.lower()\n",
        "    drug_names = [name.lower() for name in drug_names]\n",
        "    text = ''.join([i if i.isalnum() or i == ' ' else ' ' for i in text])\n",
        "\n",
        "    sentences = sent_tokenize(text, language='russian')\n",
        "\n",
        "    stemmer = PorterStemmer()\n",
        "\n",
        "    interaction_rules = []\n",
        "    previous_interaction = None\n",
        "\n",
        "    for sentence in sentences:\n",
        "        tokens = word_tokenize(sentence)\n",
        "        stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
        "        normalized_sentence = ' '.join(stemmed_tokens)\n",
        "\n",
        "        #if \"применени\" in normalized_sentence:\n",
        "        for drug_name in drug_names:\n",
        "                if drug_name in normalized_sentence:\n",
        "                    interaction_rules.append(sentence + \".\")\n",
        "                    previous_interaction = sentence\n",
        "                    break\n",
        "        else:\n",
        "            for word in stemmed_tokens:\n",
        "                #if word.endswith(\"ет\"):\n",
        "                    for drug_name in drug_names:\n",
        "                        if drug_name in normalized_sentence:\n",
        "                            if previous_interaction is not None:\n",
        "                                interaction_rules.append(previous_interaction + \" \" + sentence + \".\")\n",
        "                            else:\n",
        "                                interaction_rules.append(sentence + \".\")\n",
        "                            previous_interaction = sentence\n",
        "                            break\n",
        "                    break\n",
        "\n",
        "            if previous_interaction is not None and sentence not in interaction_rules:\n",
        "                interaction_rules.append(previous_interaction + \" \" + sentence + \".\")\n",
        "                previous_interaction = None\n",
        "\n",
        "    if not interaction_rules:\n",
        "        return \" \"\n",
        "    else:\n",
        "        return interaction_rules\n",
        "# Пример использования\n",
        "text = \"Пролонгирует действие Адапромин, усиливает эффекты противосудорожных средств, предотвращает побочные явления фенобарбитала, карбамазепина, нейролептиков. Эффект Пантогама актив усиливается при сочетании с глицином, этидроновой кислотой. При применении Пантогама следует учитывать его взаимодействие с другими лекарственными препаратами.\"\n",
        "drug = '/content/slovar.txt'\n",
        "interaction_rules = extract_interaction_rules(text,drug)\n",
        "#print(interaction_rules)\n",
        "\n",
        "def extract_keywords_from_sentences(sentences, keywords_file):\n",
        "    extracted_keywords = []\n",
        "\n",
        "    with open(keywords_file, 'r', encoding='utf-8') as file:\n",
        "        keywords = [line.strip().lower() for line in file]\n",
        "\n",
        "    for sentence in sentences:\n",
        "        lower_sentence = sentence.lower()\n",
        "        for keyword in keywords:\n",
        "            if keyword in lower_sentence:\n",
        "                extracted_keywords.append(keyword)\n",
        "\n",
        "    return extracted_keywords\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Основной код\n",
        "input_file = '/content/Текстовый документ.txt'\n",
        "output_file = '/content/vz.csv'\n",
        "drug_names_file = '/content/slovar.txt'\n",
        "\n",
        "with open(input_file, 'r', encoding='utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "last_date = \"\"\n",
        "last_drug = \"\"\n",
        "last_id = \"\"\n",
        "last_form = \"\"\n",
        "last_left_drug = \"\"\n",
        "\n",
        "with open(output_file, 'w', newline='', encoding='utf-8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['Дата изменения инструкции', 'Препарат', 'ID инструкции', 'Лекарственная форма', 'Левая часть', 'Правое ДВ', 'ID правой ФГ', 'Правая ФГ', 'Правило взаимодействия'])\n",
        "\n",
        "    for line in lines:\n",
        "        date = extract_date(line)\n",
        "        if date:\n",
        "            last_date = date\n",
        "        else:\n",
        "            date = last_date\n",
        "\n",
        "        drug = extract_drug(line)\n",
        "        if drug:\n",
        "            last_drug = drug\n",
        "        else:\n",
        "            drug = last_drug\n",
        "\n",
        "        id_num = extract_id(line)\n",
        "        if id_num:\n",
        "            last_id = id_num\n",
        "        else:\n",
        "            id_num = last_id\n",
        "\n",
        "        form = extract_form(line)\n",
        "        if form:\n",
        "            last_form = form\n",
        "        else:\n",
        "            form = last_form\n",
        "\n",
        "        left_part = left_drug(line)\n",
        "        if left_part:\n",
        "            last_left_drug = left_part\n",
        "        else:\n",
        "            left_part = last_left_drug\n",
        "\n",
        "        interactions = extract_interaction_rules(line, drug_names_file)\n",
        "        #right=extract_keywords_from_sentences(interactions,drug_names_file)\n",
        "        for interaction in interactions:\n",
        "            right_keywords = extract_keywords_from_sentences([interaction], drug_names_file)\n",
        "            print(right_keywords)\n",
        "        for keyword in right_keywords:\n",
        "            writer.writerow([date, drug, id_num, form, left_part, keyword, interaction])\n",
        "        #print(interactions)\n",
        "        #print(right)\n",
        "        #writer.writerow([date, drug, id_num, form, left_part, right,  interactions])\n",
        "\n",
        "\n",
        "# Пример использования функции\n",
        "sentences = [\"Это предложение содержит ключевое слово 'Адапален'.\",\n",
        "             \"Здесь ключевого слова нет.\",\n",
        "             \"Еще одно предложение с ключевым словом 'Авокадо плодов и соевых бобов масел неомыляемые соединения'.\"]\n",
        "\n",
        "keywords_file = \"/content/slovar.txt\"  # Файл с ключевыми словами построчно\n",
        "\n",
        "result = extract_keywords_from_sentences(sentences, keywords_file)\n",
        "#print(result)\n",
        "\n",
        "\n",
        "# Открываем CSV файл для чтения и записи\n",
        "with open('/content/vz.csv', 'r',encoding='utf-8') as file:\n",
        "    csv_reader = csv.reader(file)\n",
        "    lines = list(csv_reader)\n",
        "\n",
        "# Удаляем строки, в которых 9-ый столбец пустой\n",
        "lines = [line for line in lines if line[6].strip()]\n",
        "\n",
        "# Перезаписываем CSV файл\n",
        "with open('/content/vz.csv', 'w', newline='',encoding='utf-8') as file:\n",
        "    csv_writer = csv.writer(file)\n",
        "    csv_writer.writerows(lines)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmi1dwpxr6vm",
        "outputId": "9d091d1a-bbc7-4bc5-c24d-ec8d838c9626"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ]
    }
  ]
}